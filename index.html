<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
<!--   <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script> -->

  <!-- Google Tag Manager -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4MH67Y9HYJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4MH67Y9HYJ');
</script>

<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-P6PV2P73');</script>
  <!-- End Google Tag Manager -->

  <title>Satvik Sharma</title>
  
  <meta name="author" content="Satvik Sharma">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-P6PV2P73"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Satvik Sharma</name>
              </p>
              <p>I am a EECS Master's student in <a href="https://bair.berkeley.edu/"> BAIR</a> and the <a href="http://autolab.berkeley.edu/">AUTOLAB</a>. I did my bachelors degree at <a href="https://www.caltech.edu/">Berkeley</a> in CS.
              </p>
              <p style="text-align:center">
                <a href="mailto:satvik.sharma@berkeley.edu">Email</a> &nbsp/&nbsp
                <!-- <a href="data/Resume_Ashwin.pdf">Resume</a> &nbsp/&nbsp -->
                <!-- <a href="data/CV_Ashwin.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=0wZN6hEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Satvik1701">Github</a> &nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in algorithms for imitation learning (IL), reinforcement learning (RL), and and vision for long-horizon navigation and dextrous manipulation.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  
        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/sms_image_cropped.png' width="180"></div>
                <img src='images/sms_image_cropped.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a >
                <papertitle>Open-World Semantic Mechanical Search with Large Vision and Language Models</papertitle>
              </a>
              <br>
              <strong>Satvik Sharma</strong>,
              Kaushik Shivakumar, 
              Huang Huang, 
              Lawrence Yunliang Chen, 
              Ryan Hoque, 
              Brian Ichter, 
              Ken Goldberg
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2023
              <br>
              <a href="https://openreview.net/pdf?id=vsEWu6mMUhB">PDF</a> /
              <a href="data/2023-sms.bib">Bibtex</a>
              <p></p>
              <p>Modular framework explicitly separating VLMs and LLMs for occluded object search, which outperforms CLIP-based methods.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()" bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/lerftogo_image.png' width="180"></div>
              <img src='images/lerftogo_image.png' width="180">
            </div>
            <script type="text/javascript">
              function nlt_start() {
                document.getElementById('nlt_image').style.opacity = "1";
              }

              function nlt_stop() {
                document.getElementById('nlt_image').style.opacity = "0";
              }
              nlt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://lerftogo.github.io/desktop.html">
              <papertitle>Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping </papertitle>
            </a>
            <br>
            Adam Rashid*,
            <strong>Satvik Sharma*</strong>,
            Chung Min Kim,
            Justin Kerr,
            Lawrence Yunliang Chen,
            Angjoo Kanazawa,
            Ken Goldberg 
            <strong>(* Denotes Equal Contribution, Alphabetically Ordered)</strong></em>
            <br>
            <em>Conference on Robot Learning (CoRL)</em>, 2023 <font color="red"><strong>- Oral Presentation</strong></em></font>
            <br>
            <a href="https://lerftogo.github.io/desktop.html">Website</a> /
            <a href="https://arxiv.org/pdf/2309.07970.pdf">PDF</a> /
            <a href="data/2023-lerftogo.bib">Bibtex</a>
            <p></p>
            <p>LERF-TOGO uses CLIP and DINO features for language-specified tasks performing zero-shot semantic grasping.</p>
          </td>
        </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()" bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/2021-pg-broil.png' width="180"></div>
              <img src='images/2021-pg-broil.png' width="180">
            </div>
            <script type="text/javascript">
              function nlt_start() {
                document.getElementById('nlt_image').style.opacity = "1";
              }

              function nlt_stop() {
                document.getElementById('nlt_image').style.opacity = "0";
              }
              nlt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://sites.google.com/view/pg-broil/">
              <papertitle>Policy Gradient Bayesian Robust Optimization for Imitation Learning</papertitle>
            </a>
            <br>
            Zaynah Javed*,
            Daniel Brown*,
            <strong> Satvik Sharma</strong>,
            Jerry Zhu,
            Ashwin Balakrishna,
            Marek Petrik,
            Anca D. Dragan,
            Ken Goldberg
            <br>
            <em>International Conference on Machine Learning (ICML)</em>, 2021
            <br>
            <a href="https://sites.google.com/view/pg-broil/">Website</a> /
            <a href="https://arxiv.org/pdf/2106.06499.pdf">PDF</a> /
            <a href="data/2021-pg-broil.bib">Bibtex</a>
            <p></p>
            <p>A scalable and robust RL algorithm which optimizes for a combination of expected performance and tail risk under a distribution over learned reward functions.</p>
          </td>
        </tr>

        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()" style="margin-bottom: 10px;" >
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/fleetdagger.gif' width="180"></div>
              <img src='images/fleetdagger.gif' width="180">
            </div>
            <script type="text/javascript">
              function nlt_start() {
                document.getElementById('nlt_image').style.opacity = "1";
              }

              function nlt_stop() {
                document.getElementById('nlt_image').style.opacity = "0";
              }
              nlt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://sites.google.com/berkeley.edu/fleet-dagger/home">
              <papertitle>Fleet-DAgger: Interactive Robot Fleet Learning with Scalable Human Supervision</papertitle>
            </a>
            <br>
            Ryan Hoque, 
            Lawrence Yunliang Chen, 
            <strong> Satvik Sharma</strong>,
            Karthik Dharmarajan, 
            Brijen Thananjeyan, 
            Pieter Abbeel, 
            Ken Goldberg
            <br>
            <em>Conference on Robot Learning (CoRL)</em>, 2022 <font color="red"><strong>- Oral Presentation</strong></em></font>
            <br>
            <a href="https://sites.google.com/berkeley.edu/fleet-dagger/home">Website</a> /
            <a href="https://arxiv.org/pdf/2206.14349.pdf">PDF</a> /
            <a href="data/2022-fleetdagger.bib">Bibtex</a>
            <p></p>
            <p>We introduce new formalism, algorithms, and open-source benchmarks for "Interactive Fleet Learning": interactive learning with multiple robots and multiple humans.              .</p>
          </td>
        </tr>

        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/l2s.png' width="180"></div>
              <img src='images/l2s.png' width="180">
            </div>
            <script type="text/javascript">
              function nlt_start() {
                document.getElementById('nlt_image').style.opacity = "1";
              }

              function nlt_stop() {
                document.getElementById('nlt_image').style.opacity = "0";
              }
              nlt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning Switching Criteria for Sim2Real Transfer of Robotic Fabric Manipulation Policies</papertitle>
            </a>
            <br>
            <strong> Satvik Sharma*</strong>,
            Ellen Novoseller*, 
            Vainavi Viswanath, 
            Zaynah Javed, 
            Rishi Parikh, 
            Ryan Hoque, 
            Ashwin Balakrishna, 
            Daniel S. Brown, 
            Ken Goldberg
            <strong>(* Denotes Equal Contribution)</strong></em>
            <br>
            <em> Conference on Automation Science and Engineering (CASE)</em>, 2022
            <br>
            <a href="https://arxiv.org/pdf/2207.00911.pdf">PDF</a> /
            <a href="data/2022-case-l2s.bin">Bibtex</a>
            <p></p>
            <p>We study strategies to automatically determine when policies trained in simulation can be reliably transferred to a physical robot, specifically for a fabric smoothing task. </p>
          </td>
        </tr> 
        
        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/mog_image.png' width="180"></div>
              <img src='images/mog_image.png' width="180">
            </div>
            <script type="text/javascript">
              function nlt_start() {
                document.getElementById('nlt_image').style.opacity = "1";
              }

              function nlt_stop() {
                document.getElementById('nlt_image').style.opacity = "0";
              }
              nlt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning to Efficiently Plan Robust Frictional Multi-Object Grasps</papertitle>
            </a>
            <br>
            Wisdom C. Agboh*, 
            <strong> Satvik Sharma*</strong>,
            Kishore Srinivas, 
            Mallika Parulekar, 
            Gaurav Datta, 
            Tianshuang Qiu, 
            Jeffrey Ichnowski, 
            Eugen Solowjow, 
            Mehmet Dogar, 
            Ken Goldberg <strong>(* Denotes Equal Contribution)</strong></em>
            <br>
            <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2023
            <br>
            <a href="https://arxiv.org/pdf/2210.07420.pdf">PDF</a> /
            <a href="data/2023-mog.bin">Bibtex</a>
            <p></p>
            <p>Planning multi-object grasps under frictional constraints using a grasp success predictor network trained in real. We increase picks per hour over baselines and are robust to grasp and state uncertainity. </p>
          </td>
        </tr> 
            
        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/2023-icra-alpha.png' width="180"></div>
              <img src='images/2023-icra-alpha.png' width="180">
            </div>
            <script type="text/javascript">
              function nlt_start() {
                document.getElementById('nlt_image').style.opacity = "1";
              }

              function nlt_stop() {
                document.getElementById('nlt_image').style.opacity = "0";
              }
              nlt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Can Machines Garden? Systematically Comparing the AlphaGarden vs. Professional Horticulturalists</papertitle>
            </a>
            <br>
            Simeon Adebola, 
            Rishi Parikh, 
            Mark Presten, 
            <strong> Satvik Sharma</strong>,
            Shrey Aeron, 
            Ananth Rao, 
            Sandeep Mukherjee, 
            Tomson Qu, 
            Christina Wistrom, 
            Eugen Solowjow, 
            Ken Goldberg
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2023 <font color="red"><strong>- Outstanding Automation Paper Finalist</strong></em></font>
            <br>
            <a href="https://arxiv.org/pdf/2306.17162.pdf">PDF</a> /
            <a href="data/2023-icra-alpha.bin">Bibtex</a>
            <p></p>
            <p>Comparing the AlphaGarden system (simulator and Farmbot actuation) against professional horticulturalists in terms of plant diversity and canopy coverage. </p>
          </td>
        </tr>      


        </tbody></table>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website template from <a href="https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
