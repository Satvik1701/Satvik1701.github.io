<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
<!--   <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script> -->

  <title>Satvik Sharma</title>
  
  <meta name="author" content="Ashwin Balakrishna">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Satvik Sharma</name>
              </p>
              <p>I am a Senior Research Scientist at <a href="https://www.nuro.ai/">Nuro</a> working on using ideas from reinforcement and imitation learning for autonomous delivery. 
                I just wrapped up my PhD in Computer Science at the <a href="http://autolab.berkeley.edu/">AUTOLAB</a> in <a href="https://eecs.berkeley.edu/">UC Berkeley</a> where I developed a number of algorithms
                for safe and efficient online learning and studied applications to deformable manipulation, industrial automation, and robot grasping. I did my bachelors degree at <a href="https://www.caltech.edu/">Caltech</a> in Electrical Engineering, where I worked on a number of 
                applications of machine learning and signal processing to scientific problems, primarily in biomedical devices.
              </p>
              <p style="text-align:center">
                <a href="mailto:satvik.sharma@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="data/Resume_Ashwin.pdf">Resume</a> &nbsp/&nbsp
                <a href="data/CV_Ashwin.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=tfN6V84AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/abalakrishna123">Github</a> &nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/ashwin_newest.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ashwin_newest.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in algorithms for imitation learning (IL), reinforcement learning (RL), and control which can be reliably deployed on robotic systems. My research is primarily focused on exploring synergies between ideas in IL, RL, and control theory to develop safe and reliable algorithms for robotic control. 
                In addition, I am also excited about applications of machine learning, controls, and signal processing in a variety of contexts, including for navigation, dextrous manipulation, biomedical devices, geophysics, and aeronautics.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  
        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/sms_image.png' width="180"></div>
                <img src='images/sms_image.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a >
                <papertitle>Open-World Semantic Mechanical Search with Large Vision and Language Models</papertitle>
              </a>
              <br>
              <strong>Satvik Sharma</strong>,
              Kaushik Shivakumar, 
              Huang Huang, 
              Lawrence Yunliang Chen, 
              Ryan Hoque, 
              Brian Ichter, 
              Ken Goldberg
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2023
              <br>
              <a href="https://openreview.net/pdf?id=vsEWu6mMUhB">PDF</a> /
              <a href="data/2022-mcac.bib">Bibtex</a>
              <p></p>
              <p>Modular framework using VLMs for occluded object search which outperforms CLIP-based methods</p>
            </td>
          </tr> 
          
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/lerftogo_image.png' width="180"></div>
                <img src='images/lerftogo_image.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://lerftogo.github.io/desktop.html">
                <papertitle>Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping </papertitle>
              </a>
              <br>
              Adam Rashid*,
              <strong>Satvik Sharma*</strong>,
              Chung Min Kim,
              Justin Kerr,
              Lawrence Yunliang Chen,
              Angjoo Kanazawa,
              Ken Goldberg 
              <strong>(* Denotes Equal Contribution, Alphabetically Ordered)</strong></em>
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2023 <font color="red"><strong>- Oral Presentation</strong></em></font>
              <br>
              <a href="https://lerftogo.github.io/desktop.html">Website</a> /
              <a href="https://arxiv.org/pdf/2309.07970.pdf">PDF</a> /
              <a href="data/2023-lerftogo.bib">Bibtex</a>
              <p></p>
              <p>LERF-TOGO uses CLIP and DINO features for language-specified tasks performing zero-shot semantic grasping.</p>
            </td>
          </tr> 
          
          
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2021-mesa.png' width="180"></div>
                <img src='images/2021-mesa.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/safe-meta-rl/home">
                <papertitle>MESA: Offline Meta-RL for Safe Adaptation and Fault Tolerance</papertitle>
              </a>
              <br>
              Michael Luo,
              <strong>Ashwin Balakrishna</strong>,
              Brijen Thananjeyan,
              Suraj Nair,
              Julian Ibarz,
              Jie Tan,
              Chelsea Finn,
              Ion Stoica,
              Ken Goldberg
              <br>
              <em>NeurIPS Workshop on Safe and Robust Control of Uncertain Systems</em>, 2021 
              <br>
              <a href="https://sites.google.com/view/safe-meta-rl/home">Website</a> /
              <a href="https://arxiv.org/pdf/2112.03575.pdf">PDF</a> /
              <a href="data/2021-mesa.bib">Bibtex</a>
              <p></p>
              <p>Safe exploration by meta-learning risk measures across environments with different dynamics.</p>
            </td>
          </tr> 

          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2021-thriftydagger.png' width="180"></div>
                <img src='images/2021-thriftydagger.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/thrifty-dagger/home">
                <papertitle>ThriftyDAgger: Budget-Aware Novelty and Risk Gating for Interactive Imitation Learning</papertitle>
              </a>
              <br>
              Ryan Hoque,
              <strong>Ashwin Balakrishna</strong>,
              Ellen Novoseller,
              Albert Wilcox,
              Daniel S. Brown,
              Ken Goldberg
              <br>
              <em>Conference on Robot Learning (CoRL), 2021 - <strong>Oral Presentation</strong></em>
              <br>
              <a href="https://sites.google.com/view/thrifty-dagger/home">Website</a> /
              <a href="https://arxiv.org/pdf/2109.08273.pdf">PDF</a> /
              <a href="data/2021-thrifty-dagger.bib">Bibtex</a>
              <p></p>
              <p>An algorithm for query-efficient interactive imitation learning which learns to cede control to a supervisor when (1) in novel states or (2) in bottlenecks where task success is unlikely.</p>
            </td>
          </tr>        
          
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2021-ls3.png' width="180"></div>
                <img src='images/2021-ls3.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/latentspacesafesets">
                <papertitle>LS3: Latent Space Safe Sets for Long-Horizon Visuomotor Control of Iterative Tasks</papertitle>
              </a>
              <br>
              Albert Wilcox*,
              <strong>Ashwin Balakrishna*</strong>,
              Brijen Thananjeyan,
              Joseph E. Gonzalez,
              Ken Goldberg
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2021
              <br>
              <a href="https://sites.google.com/view/latentspacesafesets">Website</a> /
              <a href="https://arxiv.org/pdf/2107.04775.pdf">PDF</a> /
              <a href="data/2021-ls3.bib">Bibtex</a>
              <p></p>
              <p>Safe and efficient RL from image observations by leveraging suboptimal demonstrations to structure exploration and examples of constraint violations to satisfy user-specified constraints.</p>
            </td>
          </tr> 

          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2021-lazy-dagger.png' width="180"></div>
                <img src='images/2021-lazy-dagger.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2104.00053.pdf">
                <papertitle>LazyDAgger: Reducing Context Switching in Interactive Imitation Learning</papertitle>
              </a>
              <br>
              Ryan Hoque,
              <strong>Ashwin Balakrishna</strong>,
              Carl Putterman,
              Michael Luo,
              Daniel S. Brown,
              Daniel Seita,
              Brijen Thananjeyan,
              Ellen Novoseller,
              Ken Goldberg
              <br>
              <em>Conference on Automation Science and Engineering (CASE)</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2104.00053.pdf">PDF</a> /
              <a href="data/2021-lazy-dagger.bib">Bibtex</a>
              <p></p>
              <p>An algorithm for reducing supervisor burden by limiting context switches in interactive imitation learning.</p>
            </td>
          </tr> 
        
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2021-pg-broil.png' width="180"></div>
                <img src='images/2021-pg-broil.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/pg-broil/">
                <papertitle>Policy Gradient Bayesian Robust Optimization for Imitation Learning</papertitle>
              </a>
              <br>
              Zaynah Javed*,
              Daniel Brown*,
              Satvik Sharma,
              Jerry Zhu,
              <strong>Ashwin Balakrishna</strong>,
              Marek Petrik,
              Anca D. Dragan,
              Ken Goldberg
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2021
              <br>
              <a href="https://sites.google.com/view/pg-broil/">Website</a> /
              <a href="https://arxiv.org/pdf/2106.06499.pdf">PDF</a> /
              <a href="data/2021-pg-broil.bib">Bibtex</a>
              <p></p>
              <p>A scalable and robust RL algorithm which optimizes for a combination of expected performance and tail risk under a distribution over learned reward functions.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-recovery-rl.png' width="180"></div>
                <img src='images/2020-recovery-rl.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/berkeley.edu/recovery-rl/">
                <papertitle>Recovery RL: Safe Reinforcement Learning with Learned Recovery Zones</papertitle>
              </a>
              <br>
              Brijen Thananjeyan*,
              <strong>Ashwin Balakrishna*</strong>,
              Suraj Nair,
              Michael Luo,
              Krishnan Srinivasan,
              Minho Hwang,
              Joseph E. Gonzalez,
              Julian Ibarz,
              Chelsea Finn,
              Ken Goldberg
              <br>
              <em>Robotics and Automation Letters (RA-L) Journal and International Conference on Robotics and Automation (ICRA)</em>, 2021 - <strong>Mentioned in <a href="https://ai.googleblog.com/2021/01/google-research-looking-back-at-2020.html">Google AI Year in Review</a></strong>
              <br>
              <a href="https://sites.google.com/berkeley.edu/recovery-rl/">Website</a> /
              <a href="https://arxiv.org/pdf/2010.15920.pdf">PDF</a> /
              <a href="data/2020-recovery-rl.bib">Bibtex</a>
<!--          <br>
              Mentioned in <a href="https://ai.googleblog.com/2021/01/google-research-looking-back-at-2020.html">Google AI Year in Review</a>
              <br> -->
              <p></p>
              <p>An algorithm for safe reinforcement learning which utilizes a set of offline data to learn about constraints before policy learning and a pair of policies which seperate the often conflicting objectives of task directed exploration and constraint satisfaction to learn contact rich and visuomotor control tasks.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-abc-lmpc.png' width="180"></div>
                <img src='images/2020-abc-lmpc.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/abc-lmpc/home">
                <papertitle>ABC-LMPC: Safe Sample-Based Learning MPC for Stochastic Nonlinear Dynamical Systems with Adjustable Boundary Conditions</papertitle>
              </a>
              <br>
              Brijen Thananjeyan*,
              <strong>Ashwin Balakrishna*</strong>,
              Ugo Rosolia,
              Joseph E. Gonzalez,
              Aaron Ames,
              Ken Goldberg
              <br>
              <em>Algorithmic Foundations of Robotics (WAFR)</em>, 2020 - <strong>Invited to IJRR Special Issue</strong></em> 
              <br>
              <a href="https://sites.google.com/view/abc-lmpc/home">Website</a> /
              <a href="https://arxiv.org/pdf/2003.01410.pdf">PDF</a> /
              <a href="data/2020-abc-lmpc.bib">Bibtex</a>
              <p></p>
              <p>An MPC-based algorithm for robotic control (ABC-LMPC) with (1) performance and safety guarantees for stochastic nonlinear systems and (2) the ability to continuously explore the environment and expand the controller domain.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-saved.png' width="180"></div>
                <img src='images/2020-saved.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/safetyaugmentedvalueestimation/home">
                <papertitle>Safety Augmented Value Estimation from Demonstrations (SAVED): Safe Deep Model-Based RL for Sparse Cost Robotic Tasks</papertitle>
              </a>
              <br>
              Brijen Thananjeyan*,
              <strong>Ashwin Balakrishna*</strong>,
              Ugo Rosolia,
              Felix Li,
              Rowan McAllister,
              Joseph E. Gonzalez,
              Sergey Levine,
              Francesco Borrelli,
              Ken Goldberg
              <br>
              <em>Robotics and Automation Letters (RA-L) Journal and International Conference on Robotics and Automation (ICRA)</em>, 2020  
              <br>
              <a href="https://sites.google.com/view/safetyaugmentedvalueestimation/home">Website</a> /
              <a href="https://arxiv.org/pdf/1905.13402.pdf">PDF</a> /
              <a href="data/2020-saved.bib">Bibtex</a>
              <p></p>
              <p>A new algorithm for safe and efficient reinforcement learning (SAVED) which leverages a small set of suboptimal demonstrations and prior task successes to structure exploration. SAVED also provides a mechanism for handling state-space constraints by leveraging probabilistic estimates of system dynamics.</p>
            </td>
          </tr> 
    
        <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2019-converging-supervisors.png' width="180"></div>
                <img src='images/2019-converging-supervisors.png' width="180">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1907.03423.pdf">
                <papertitle>On-Policy Robot Imitation Learning from a Converging Supervisor</papertitle>
              </a>
              <br>
              <strong>Ashwin Balakrishna*</strong>,
              Brijen Thananjeyan*,
              Jonathan Lee,
              Felix Li,
              Arsh Zahed,
              Joseph E. Gonzalez,
              Ken Goldberg
              <br>
              <em>Conference on Robot Learning (CoRL), 2019 - <strong>Oral Presentation</strong></em>
              <br>
              <a href="https://arxiv.org/pdf/1907.03423.pdf">PDF</a> /
              <a href="data/2019-converging-supervisors.bib">Bibtex</a>
              <p></p>
              <p>A new formulation of imitiation learning from a non-stationary supervisor, associated theoretical analysis, and a practical algorithm to apply this formulation to develeop an RL algorithm which combines the sample efficiency of model-based RL and the fast policy evaluation enabled by model-free policies.</p>
            </td>
        </tr>  
    
        </tbody></table>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Algorithms for Robotic Manipulation</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
       <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2021-legs.png' width="180"></div>
                <img src='images/2021-legs.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/legs-exp-grasping">
                <papertitle>LEGS: Learning Efficient Grasping Sets for Exploratory Grasping</papertitle>
              </a>
              <br>
              Leitan Fu,
              Michael Danielczuk,
              <strong>Ashwin Balakrishna</strong>,
              Daniel S. Brown,
              Jeffrey Ichnowski,
              Eugen Solowjow,
              Ken Goldberg
              <br>
              <em>International Conference on Robotics and Automation (ICRA)</em>, 2022
              <br>
              <a href="https://sites.google.com/view/legs-exp-grasping">Website</a> /
              <a href="https://arxiv.org/pdf/2111.15002.pdf">PDF</a> /
              <a href="data/2021-legs.bib">Bibtex</a>
              <p></p>
              <p>An algorithm for rapidly exploring large sets of grasps on objects with challenging geometries.</p>
            </td>
          </tr> 

         <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/2021-multi-cable.png' width="180"></div>
              <img src='images/2021-multi-cable.png' width="180">
            </div>
            <script type="text/javascript">
              function nlt_start() {
                document.getElementById('nlt_image').style.opacity = "1";
              }

              function nlt_stop() {
                document.getElementById('nlt_image').style.opacity = "0";
              }
              nlt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/pdf/2106.02252.pdf">
              <papertitle>Disentangling Dense Multiple-Cable Knots</papertitle>
            </a>
            <br>
            Vainavi Viswanath*,
            Jennifer Grannen*,
            Priya Sundaresan*,
            Brijen Thananjeyan,
            <strong>Ashwin Balakrishna</strong>,
            Ellen Novoseller,
            Jeffrey Ichnowski,
            Michael Laskey,
            Joseph E. Gonzalez,
            Ken Goldberg
            <br>
            <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2021
            <br>
            <a href="https://arxiv.org/pdf/2106.02252.pdf">Website</a> /
            <a href="https://arxiv.org/pdf/2106.02252.pdf">PDF</a> /
            <a href="data/2021-multi-cable.bib">Bibtex</a>
            <p></p>
            <p>Learning to disentangle multiple cables in a variety of different knotted configurations.</p>
          </td>
         </tr> 

         <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/2021-kitting.png' width="180"></div>
              <img src='images/2021-kitting.png' width="180">
            </div>
            <script type="text/javascript">
              function nlt_start() {
                document.getElementById('nlt_image').style.opacity = "1";
              }

              function nlt_stop() {
                document.getElementById('nlt_image').style.opacity = "0";
              }
              nlt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/BerkeleyAutomation/Kit-Net">
              <papertitle>Kit-Net: Self-Supervised Learning to Kit Novel 3D Objects into Novel 3D Cavities</papertitle>
            </a>
            <br>
            Shivin Devgon,
            Jeffrey Ichnowski,
            Michael Danielczuk,
            Daniel S. Brown,
            <strong>Ashwin Balakrishna</strong>,
            Shirin Joshi,
            Eduardo M. C. Rocha,
            Eugen Solowjow,
            Ken Goldberg
            <br>
            <em>Conference on Automation Science and Engineering (CASE)</em>, 2021
            <br>
            <a href="https://github.com/BerkeleyAutomation/Kit-Net">Website</a> /
            <a href="https://arxiv.org/pdf/2107.05789.pdf">PDF</a> /
            <a href="data/2021-kitting.bib">Bibtex</a>
            <p></p>
            <p>Learning to kit novel 3D objects in complex 3D cavities with self-supervised rotation estimation.</p>
          </td>
         </tr> 
          
         <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/2021-recovery-untangling.png' width="180"></div>
              <img src='images/2021-recovery-untangling.png' width="180">
            </div>
            <script type="text/javascript">
              function nlt_start() {
                document.getElementById('nlt_image').style.opacity = "1";
              }

              function nlt_stop() {
                document.getElementById('nlt_image').style.opacity = "0";
              }
              nlt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://sites.google.com/berkeley.edu/non-planar-untangling/">
              <papertitle>Untangling Dense Non-Planar Knots by Learning Manipulation Features and Recovery Policies</papertitle>
            </a>
            <br>
            Priya Sundaresan*,
            Jennifer Grannen*,
            Brijen Thananjeyan,
            <strong>Ashwin Balakrishna</strong>,
            Jeffrey Ichnowski,
            Ellen Novoseller,
            Minho Hwang, 
            Michael Laskey,
            Joseph E. Gonzalez,
            Ken Goldberg
            <br>
            <em>Robotics Science and Systems (RSS)</em>, 2021
            <br>
            <a href="https://sites.google.com/berkeley.edu/non-planar-untangling/">Website</a> /
            <a href="http://www.roboticsproceedings.org/rss17/p013.pdf">PDF</a> /
            <a href="data/2021-recovery-untangling.bib">Bibtex</a>
            <p></p>
            <p>Learning robust untangling policies with learned progress detection and recovery behaviors.</p>
          </td>
        </tr> 
          
        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-fabric-descriptors.png' width="160"></div>
                <img src='images/2020-fabric-descriptors.png' width="160">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/fabric-descriptors/home">
                <papertitle>Learning Dense Visual Correspondences in Simulation to Smooth and Fold Real Fabrics</papertitle>
              </a>
              <br>
              Aditya Ganapathi,
              Priya Sundaresan,
              Brijen Thananjeyan,
              <strong>Ashwin Balakrishna</strong>,
              Daniel Seita,
              Jennifer Grannen,
              Minho Hwang,
              Ryan Hoque, 
              Joseph E. Gonzalez,
              Nawid Jamali,
              Katsu Yamane,
              Soshi Iba,
              Ken Goldberg
              <br>
              <em>International Conference on Robotics and Automation (ICRA)</em>, 2021
              <br>
              <a href="https://sites.google.com/view/fabric-descriptors/home">Website</a> /
              <a href="https://arxiv.org/pdf/2003.12698.pdf">PDF</a> /
              <a href="data/2020-fabric-descriptors.bib">Bibtex</a>
              <p></p>
              <p>A general method for multi-task fabric manipulation using learned visual correspondences which can be applied across different robots to manipulate fabrics of varying shapes and colors.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-grasp-exp.png' width="180"></div>
                <img src='images/2020-grasp-exp.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/exploratory-grasping/home">
                <papertitle>Exploratory Grasping: Asymptotically Optimal Algorithms for Grasping Challenging Polyhedral Objects</papertitle>
              </a>
              <br>
              Michael Danielczuk*,
              <strong>Ashwin Balakrishna*</strong>,
              Daniel Brown,
              Shivin Devgon,
              Ken Goldberg
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2020
              <br>
              <a href="https://sites.google.com/view/exploratory-grasping/home">Website</a> /
              <a href="https://arxiv.org/pdf/2011.05632.pdf">PDF</a> /
              <a href="data/2020-grasp-exp.bib">Bibtex</a>
              <p></p>
              <p>An asymptotically optimal algorithm for rapidly learning to grasp new objects through online exploration.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-untangling.png' width="180"></div>
                <img src='images/2020-untangling.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/berkeley.edu/corl2020ropeuntangling/home">
                <papertitle>Untangling Dense Knots by Learning Task-Relevant Keypoints</papertitle>
              </a>
              <br>
              Jennifer Grannen*,
              Priya Sundaresan*,
              Brijen Thananjeyan,
              Jeffrey Ichnowski,
              <strong>Ashwin Balakrishna</strong>,
              Minho Hwang,
              Vainavi Viswanath,
              Michael Laskey,
              Joseph E. Gonzalez,
              Ken Goldberg
              <br>
              <em>Conference on Robot Learning (CoRL), 2020 - <strong>Oral Presentation</strong></em>
              <br>
              <a href="https://sites.google.com/berkeley.edu/corl2020ropeuntangling/home">Website</a> /
              <a href="https://arxiv.org/pdf/2011.04999.pdf">PDF</a> /
              <a href="data/2020-untangling.bib">Bibtex</a>
              <p></p>
              <p>Algorithms for untying dense knots in cables in the real world.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-smoothing.png' width="180"></div>
                <img src='images/2020-smoothing.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/fabric-smoothing">
                <papertitle>Deep Imitation Learning of Sequential Fabric Smoothing from an Algorithmic Supervisor</papertitle>
              </a>
              <br>
              Daniel Seita,
              Aditya Ganapathi,
              Ryan Hoque,
              Minho Hwang,
              Edward Cen,
              Ajay Kumar Tanwani,
              <strong>Ashwin Balakrishna</strong>,
              Brijen Thananjeyan,
              Jeffrey Ichnowski,
              Nawid Jamali,
              Katsu Yamane,
              Soshi Iba,
              John F. Canny,
              Ken Goldberg
              <br>
              <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2020  
              <br>
              <a href="https://sites.google.com/view/fabric-smoothing">Website</a> /
              <a href="https://arxiv.org/abs/1910.04854">PDF</a> /
              <a href="data/2020-smoothing.bib">Bibtex</a>
              <p></p>
              <p>A new fabric simulator for learning fabric smoothing policies and learned policies which successfully smooth fabric in simulation and transfer to physical robotic systems.</p>
            </td>
          </tr>
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-mmgsd.png' width="180"></div>
                <img src='images/2020-mmgsd.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2010.04339.pdf">
                <papertitle>MMGSD: Multi-Modal Gaussian Shape Descriptors for Correspondence Matching in 1D and 2D Deformable Objects</papertitle>
              </a>
              <br>
              Aditya Ganapathi*,
              Priya Sundaresan*,
              Brijen Thananjeyan,
              <strong>Ashwin Balakrishna</strong>,
              Daniel Seita,
              Ryan Hoque,
              Joseph E. Gonzalez,
              Ken Goldberg
              <br>
              <em>International Conference on Intelligent Robots and Systems (IROS) Workshop on Managing Deformation</em>, 2020 
              <br>
              <a href="https://arxiv.org/pdf/2010.04339.pdf">PDF</a> /
              <a href="data/2020-mmgsd.bib">Bibtex</a>
              <p></p>
              <p>A new algorithm for learning symmetry aware visual representations for deformable objects.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-tslp.png' width="180"></div>
                <img src='images/2020-tslp.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/2020-TSLP.pdf">
                <papertitle>Accelerating Grasp Exploration by Leveraging Learned Priors</papertitle>
              </a>
              <br>
              Katherine Li*,
              Michael Danielczuk*,
              <strong>Ashwin Balakrishna*</strong>,
              Vishal Satish,
              Ken Goldberg
              <br>
              <em>Conference on Automation Science and Engineering (CASE)</em>, 2020
              <br>
              <a href="data/2020-TSLP.pdf">PDF</a> /
              <a href="data/2020-tslp.bib">Bibtex</a>
              <p></p>
              <p>An algorithm for leveraging priors from general purpose grasping systems to accelerate online grasp exploration on novel, difficult to grasp objects.</p>
            </td>
         </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-orienting.png' width="180"></div>
                <img src='images/2020-orienting.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://berkeleyautomation.github.io/Orienting_Novel_3D_Objects/">
                <papertitle>Orienting Novel 3D Objects Using Self-Supervised Learning of Rotation Transforms</papertitle>
              </a>
              <br>
              Shivin Devgon,
              Jeffrey Ichnowski,
              <strong>Ashwin Balakrishna</strong>,
              Harry Zhang,
              Ken Goldberg
              <br>
              <em>Conference on Automation Science and Engineering (CASE)</em>, 2020
              <br>
              <a href="https://berkeleyautomation.github.io/Orienting_Novel_3D_Objects/">Website</a> /
              <a href="https://arxiv.org/pdf/2105.14246.pdf">PDF</a> /
              <a href="data/2020-orienting.bib">Bibtex</a>
              <p></p>
              <p>A self-supervised algorithm which learns to orient unseen objects with unknown geometry given only a depth image observation of the desired orientation.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-vsf.png' width="180"></div>
                <img src='images/2020-vsf.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/fabric-vsf/">
                <papertitle>VisuoSpatial Foresight (VSF) for Multi-Step, Multi-Task Fabric Manipulation</papertitle>
              </a>
              <br>
              Ryan Hoque*,
              Daniel Seita*,
              <strong>Ashwin Balakrishna</strong>,
              Aditya Ganapathi,
              Ajay Tanwani,
              Nawid Jamali,
              Katsu Yamane,
              Soshi Iba,
              Ken Goldberg
              <br>
              <em>Autonomous Robots Journal Special Issue, 2021 and Robotics Science and Systems (RSS)</em>, 2020</em> 
              <br>
              <a href="https://sites.google.com/view/fabric-vsf/">Website</a> /
              <a href="https://arxiv.org/pdf/2003.09044.pdf">PDF</a> /
              <a href="data/2020-vsf.bib">Bibtex</a>
              <p></p>
              <p>A method for multi task fabric manipulation by leveraging recent advances in video prediction and depth sensing.</p>
            </td>
          </tr>  
          
          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2020-rope-descriptors.png' width="180"></div>
                <img src='images/2020-rope-descriptors.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/ropemanipdescriptors/home">
                <papertitle>Learning Interpretable and Transferable Rope Manipulation Policies Using Depth Sensing and Dense Object Descriptors</papertitle>
              </a>
              <br>
              Priya Sundaresan,
              Jennifer Grannen,
              Brijen Thananjeyan,
              <strong>Ashwin Balakrishna</strong>,
              Michael Laskey,
              Kevin Stone,
              Joseph E. Gonzalez,
              Ken Goldberg
              <br>
              <em>International Conference on Robotics and Automation (ICRA)</em>, 2020  
              <br>
              <a href="https://sites.google.com/view/ropemanipdescriptors/home">Website</a> /
              <a href="https://arxiv.org/pdf/2003.01835.pdf">PDF</a> /
              <a href="data/2020-rope-descriptors.bib">Bibtex</a>
              <p></p>
              <p>An algorithm for learning visual correspondences for highly deformable objects and an associated controller which is used to manipulate rope into a variety of different arrangements either by learning from demonstrations or by designing interpretable geometric policies on top of the learned visual representation.</p>
            </td>
          </tr> 
  
            <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2019-pushing.png' width="180"></div>
                <img src='images/2019-pushing.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://goldberg.berkeley.edu/pubs/2019-CASE-zisu-singulating.pdf">
                <papertitle>Automating Planar Object Singulation by Linear Pushing with Single-point and Multi-point Contacts</papertitle>
              </a>
              <br>
              Zisu Dong,
              Sanjay Krishnan,
              Sona Dolasia,
              <strong>Ashwin Balakrishna</strong>,
              Michael Danielczuk,
              Ken Goldberg
              <br>
              <em>Conference on Automation Science and Engineering (CASE)</em>, 2019  
              <br>
              <a href="https://goldberg.berkeley.edu/pubs/2019-CASE-zisu-singulating.pdf">PDF</a> /
              <a href="data/2019-pushing.bib">Bibtex</a>
              <p></p>
              <p>An efficient geometric algorithm (ClusterPush) for singulating a set of clustered planar objects.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2019-mech-search.png' width="180"></div>
                <img src='images/2019-mech-search.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://ai.stanford.edu/mech-search/">
                <papertitle>Mechanical Search: Multi-Step Retrieval of a Target Object Occluded by Clutter</papertitle>
              </a>
              <br>
              Michael Danielczuk*,
              Andrey Kurenkov*,
              <strong>Ashwin Balakrishna</strong>,
              Matthew Matl,
              David Wang,
              Roberto Martin-Martin,
              Animesh Garg,
              Silvio Savarase,
              Ken Goldberg
              <br>
              <em>International Conference on Robotics and Automation (ICRA)</em>, 2019
              <br>
              <a href="http://ai.stanford.edu/mech-search/">Website</a> /
              <a href="https://arxiv.org/pdf/1903.01588.pdf">PDF</a> /
              <a href="data/2019-mech-search.bib">Bibtex</a>
              <p></p>
              <p>Formulation and algorithms for the problem of efficiently identifying and retrieving a specific object in a cluttered environment.</p>
            </td>
          </tr> 
          
        </tbody></table>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Machine Learning for Physical Sciences</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2019-hemodynamics.png' width="180"></div>
                <img src='images/2019-hemodynamics.png' width="180">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC6879107&blobtype=pdf">
                <papertitle>Fabry-Pérot optical sensor and portable detector for monitoring high-resolution ocular hemodynamics</papertitle>
              </a>
              <br>
              Jeong Oen Lee,
              Vinayak Narasimhan,
              <strong>Ashwin Balakrishna</strong>,
              Marcus R. Smith
              Juan Du,
              David Stretavan,
              Hyuck Choo
              <br>
              <em>Photonics Technology Letters</em>, 2019
              <br>
              <a href="https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC6879107&blobtype=pdf">PDF</a> /
              <a href="data/2019-hemodynamics.bib">Bibtex</a>
              <p></p>
              <p>High resolution measurement of both intraocular pressure and ocular pulsation profiles using an implmantable micro-optical sensor and portable optical detector.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2018-earthquake.png' width="140"></div>
                <img src='images/2018-earthquake.png' width="140">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1901.03467.pdf">
                <papertitle>Reliable Real-time Seismic Signal/Noise Discrimination with Machine Learning</papertitle>
              </a>
              <br>
              Men-Andrin Meier,
              Zachary E. Ross,
              Anshul Ramachandran,
              <strong>Ashwin Balakrishna</strong>,
              Suraj Nair,
              Peter Kundzicz,
              Zefeng Li,
              Jennifer Andrews,
              Egill Hauksson,
              Yisong Yue
              <br>
              <em>Journal of Geophysical Research: Solid Earth</em>, 2018
              <br>
              <a href="https://arxiv.org/pdf/1901.03467.pdf">PDF</a> /
              <a href="data/2018-earthquake.bib">Bibtex</a>
              <p></p>
              <p>Algorithms for rapid and reliable earthquake detection for earthquake early warning systems.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2018-EVSE.png' width="160"></div>
                <img src='images/2018-EVSE.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1804.00714.pdf">
                <papertitle>Predicting Electric Vehicle Charging Station Usage: Using Machine Learning to Estimate Individual Station Statistics from Physical Configurations of Charging Station Networks</papertitle>
              </a>
              <br>
              Anshul Ramachandran,
              <strong>Ashwin Balakrishna</strong>,
              Peter Kundzicz,
              Anirudh Neti
              <br>
              <em>Preprint</em>, 2018  
              <br>
              <a href="https://arxiv.org/pdf/1804.00714.pdf">PDF</a> /
              <a href="data/2018-EVSE.bib">Bibtex</a>
              <p></p>
              <p>Algorithms for predicting electrical vehicle power usage for different charging network designs.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2018-IOP-algorithms.png' width="180"></div>
                <img src='images/2018-IOP-algorithms.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/2018-IOP-Algorithms.pdf">
                <papertitle>Machine Learning Methods for Rapid, Real-Time Pressure Readout from an Optics-Based Intraocular Pressure Sensor</papertitle>
              </a>
              <br>
              <strong>Ashwin Balakrishna</strong>,
              Jeong Oen Lee,
              Hyuck Choo
              <br>
              <em>Preprint</em>, 2018  
              <br>
              <a href="data/2018-IOP-Algorithms.pdf">PDF</a> /
              <a href="data/2018-IOP-algorithms.bib">Bibtex</a>
              <p></p>
              <p>An evaluation of different machine learning algorithms for intraocular pressure measurement.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2017-iop-monitoring.png' width="160"></div>
                <img src='images/2017-iop-monitoring.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.nature.com/articles/micronano201757.pdf">
                <papertitle>A microscale optical implant for continuous in vivo monitoring of intraocular pressure</papertitle>
              </a>
              <br>
              Jeong Oen Lee,
              Haeri Park,
              Juan Du,
              <strong>Ashwin Balakrishna</strong>,
              Oliver Chen,
              David Stretavan,
              Hyuck Choo
              <br>
              <em>Nature: Microsystems and Nanoengineering</em>, 2017  
              <br>
              <a href="https://www.nature.com/articles/micronano201757.pdf">PDF</a> /
              <a href="data/2017-iop-monitoring.bib">Bibtex</a>
              <p></p>
              <p>A new microscale implantable sensor and associated algorithms for accurate and convenient measurement of intraocular pressure.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2017-positioning-sensor.png' width="180"></div>
                <img src='images/2017-positioning-sensor.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5449164/pdf/opth-11-939.pdf">
                <papertitle>Novel positioning sensor with real-time feedback for improved postoperative positioning: pilot study in control subjects</papertitle>
              </a>
              <br>
              Frank Brodie,
              David Ramirez*,
              Sundar Pandian*,
              Kelly Woo,
              <strong>Ashwin Balakrishna</strong>,
              Eugene De Juan,
              Hyuck Choo,
              Robert H Grubbs
              <br>
              <em>Clinical Opthalmology</em>, 2017  
              <br>
              <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5449164/pdf/opth-11-939.pdf">PDF</a> /
              <a href="data/2017-positioning-sensor.bib">Bibtex</a>
              <p></p>
              <p>A new wearable, wireless sensor to aid postoperative recovery from retinal detachment surgery.</p>
            </td>
          </tr> 
          
          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2016-positioning-sensor.png' width="180"></div>
                <img src='images/2016-positioning-sensor.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5449164/pdf/opth-11-939.pdf">
                <papertitle>Validation of sensor for postoperative positioning with intraocular gas</papertitle>
              </a>
              <br>
              Frank Brodie,
              Kelly Woo,
              <strong>Ashwin Balakrishna</strong>,
              Hyuck Choo,
              Robert H Grubbs
              <br>
              <em>Clinical Opthalmology</em>, 2016  
              <br>
              <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4888728/pdf/opth-10-955.pdf">PDF</a> /
              <a href="data/2016-positioning-sensor.bib">Bibtex</a>
              <p></p>
              <p>A simple, wearable electromechanical sensor to aid postoperative recovery from retinal detachment surgery.</p>
            </td>
          </tr>
          
          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2016-nn-iop.png' width="180"></div>
                <img src='images/2016-nn-iop.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/2016-nn-iop.pdf">
                <papertitle>A Neural Network Approach to Monitor Intraocular Pressure for Glaucoma Diagnosis</papertitle>
              </a>
              <br>
              <strong>Ashwin Balakrishna</strong>,
              Oliver Chen,
              Jeong Oen Lee,
              Hyuck Choo
              <br>
              <em>Progress In Electromagnetics Research Symposium (PIERS)</em>, 2016  
              <br>
              <a href="data/2016-nn-iop.pdf">PDF</a> /
              <a href="data/2016-nn-iop.bib">Bibtex</a>
              <p></p>
              <p>A neural network based algorithm to efficiently extract accurate intraocular pressure measurements from reflection spectra from an optics-based intraocular pressure sensor.</p>
            </td>
          </tr>
          
          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2016-iop-invivo.png' width="180"></div>
                <img src='images/2016-iop-invivo.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/2016-iop-invivo.pdf">
                <papertitle>In vivo Intraocular Pressure Monitoring using Implantable Optomechanical Sensor</papertitle>
              </a>
              <br>
              Jeong Oen Lee,
              Haero Park,
              Juan Du,
              Vinayak Narasimhan,
              <strong>Ashwin Balakrishna</strong>,
              Oliver Chen,
              David Stretavan,
              Hyuck Choo
              <br>
              <em>Interenational Symposium on Optomechatronic Technology (ISOT)</em>, 2016  
              <br>
              <a href="data/2016-iop-invivo.pdf">PDF</a> /
              <a href="data/2016-iop-invivo.bib">Bibtex</a>
              <p></p>
              <p>Evaluation of a new optics-based intraocular pressure sensor in live rabbits.</p>
            </td>
          </tr>
          
          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/2016-vocal-power.png' width="160"></div>
                <img src='images/2016-vocal-power.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://choolab.caltech.edu/pdfs/2016%20IEEE%20MEMS%20Energy%20Harvesting.pdf">
                <papertitle>Efficient Power Generation from Vocal Folds Vibrations for Medical Electronic Implants</papertitle>
              </a>
              <br>
              Hyunjun Cho,
              <strong>Ashwin Balakrishna</strong>,
              Yuan Ma,
              Jeong Oen Lee,
              Hyuck Choo
              <br>
              <em>International Conference on Micro-Electro-Mechanical Systems (MEMS)</em>, 2016  
              <br>
              <a href="http://choolab.caltech.edu/pdfs/2016%20IEEE%20MEMS%20Energy%20Harvesting.pdf">PDF</a> /
              <a href="data/2016-vocal-power.bib">Bibtex</a>
              <p></p>
              <p>A piezoelectric based device to harvest power from human vocal cord vibrations.</p>
            </td>
          </tr>
          
          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/traj_opt_solar_flight_2014.png' width="180"></div>
                <img src='images/traj_opt_solar_flight_2014.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/traj_opt_solar_flight_2014.pdf">
                <papertitle>Optimal Control Strategies for Trajectory Optimization with Applications to Continuous Solar Flight</papertitle>
              </a>
              <br>
              <strong>Ashwin Balakrishna</strong>
              <br>
              <em>INFORMS Annual Meeting, High School Mathematical Science Journal, Intel Science Talent Search Semifinalist</em>, 2014  
              <br>
              <a href="data/traj_opt_solar_flight_2014.pdf">PDF</a> /
              <a href="data/traj_opt_solar_flight.bib">Bibtex</a>
              <p></p>
              <p>Mathematical model and algorithm for controlling continuously flying solar aircraft.</p>
            </td>
          </tr> 
          
        </tbody></table>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website template from <a href="https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
